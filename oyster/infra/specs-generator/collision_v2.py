#!/usr/bin/env python3
"""
Spec ç¢°æ’ç³»ç»Ÿ v2 - åŸºäº LLaMEA æ€æƒ³ - å®Œæ•´ç‰ˆ

æ ¸å¿ƒæœºåˆ¶ï¼š
- Fitness-guided: ç”¨æµ‹è¯•ç»“æœæŒ‡å¯¼ç”Ÿæˆ
- è¿­ä»£è¿›åŒ–: ä¸Šä¸€è½®ç»“æœâ†’ä¸‹ä¸€è½®ç§å­
- Dispatch é›†æˆ: çœŸæ­£è°ƒåº¦åˆ°é›†ç¾¤æ‰§è¡Œ
- çœŸå®æµ‹è¯•: fitness = æµ‹è¯•é€šè¿‡ç‡
"""

import sys
import os
import json
import argparse
import subprocess
import time
import re
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass, field
from enum import Enum

# ============== é…ç½® ==============
MAX_GENERATIONS = 20
POPULATION_SIZE = 5
MUTATION_RATE = 0.4
CROSSOVER_RATE = 0.3
MAX_TOKENS = 16384
TEMPERATURE = 0.7
DISPATCH_TIMEOUT = 600  # 10 åˆ†é’Ÿè¶…æ—¶

# ============== å¼ºéªŒæ”¶æ ‡å‡†æƒé‡ ==============
# pytest å…¨ç»¿ (50%) + black/flake8 (20%) + mypy (20%) + é›†æˆæµ‹è¯• (10%)
WEIGHT_PYTEST = 0.50
WEIGHT_LINT = 0.20
WEIGHT_MYPY = 0.20
WEIGHT_INTEGRATION = 0.10


class FitnessLevel(Enum):
    EXCELLENT = 1.0
    GOOD = 0.8
    PARTIAL = 0.5
    POOR = 0.2
    FAILED = 0.0


@dataclass
class SpecIndividual:
    id: str
    spec_content: str
    fitness: float = 0.0
    test_passed: int = 0
    test_total: int = 0
    error_msg: str = ""
    parent_ids: List[str] = field(default_factory=list)
    generation: int = 0
    mutations: int = 0
    code_path: str = ""
    acceptance: Optional[AcceptanceResult] = None  # å¼ºéªŒæ”¶ç»“æœ

    @property
    def fitness_level(self) -> FitnessLevel:
        if self.fitness >= 1.0:
            return FitnessLevel.EXCELLENT
        elif self.fitness >= 0.8:
            return FitnessLevel.GOOD
        elif self.fitness >= 0.5:
            return FitnessLevel.PARTIAL
        elif self.fitness >= 0.2:
            return FitnessLevel.POOR
        return FitnessLevel.FAILED


# ============== LLM æ¥å£ ==============
def call_llm(
    prompt: str, system_prompt: str = None, temperature: float = TEMPERATURE
) -> str:
    import urllib.request

    key_file = os.path.expanduser("~/.oyster-keys/minimax.env")
    API_KEY = os.environ.get("MINIMAX_API_KEY")
    if not API_KEY and os.path.exists(key_file):
        for line in open(key_file):
            if line.startswith("export MINIMAX_API_KEY="):
                API_KEY = line.split("=", 1)[1].strip().strip('"')
                break

    if not API_KEY:
        raise Exception("MINIMAX_API_KEY not found")

    messages = []
    if system_prompt:
        messages.append({"role": "system", "content": system_prompt})
    messages.append({"role": "user", "content": prompt})

    data = json.dumps(
        {
            "model": "MiniMax-M2.5",
            "messages": messages,
            "max_tokens": MAX_TOKENS,
            "temperature": temperature,
        }
    ).encode()

    req = urllib.request.Request(
        "https://api.minimax.io/v1/text/chatcompletion_v2",
        data=data,
        headers={
            "Authorization": f"Bearer {API_KEY}",
            "Content-Type": "application/json",
        },
    )

    try:
        with urllib.request.urlopen(req, timeout=180) as resp:
            result = json.loads(resp.read())
            return result["choices"][0]["message"]["content"]
    except Exception as e:
        print(f"  âš ï¸ LLM è°ƒç”¨å¤±è´¥: {e}")
        return ""


# ============== Spec ä¿å­˜ ==============
def save_spec(
    spec_content: str, project: str, individual_id: str, generation: int
) -> str:
    """ä¿å­˜ spec åˆ°æ–‡ä»¶"""
    spec_dir = Path(f"~/Downloads/specs/{project}/collision").expanduser()
    spec_dir.mkdir(parents=True, exist_ok=True)

    filename = f"gen{generation:02d}_{individual_id}.md"
    path = spec_dir / filename
    path.write_text(spec_content)

    return str(path)


# ============== Dispatch é›†æˆ ==============
def run_dispatch(project: str, spec_path: str) -> Dict:
    """è¿è¡Œ dispatch æ‰§è¡Œ spec"""
    print(f"    ğŸ“¤ è°ƒåº¦åˆ° dispatch...")

    # 1. å¯åŠ¨ dispatch
    cmd = f"python3 ~/Downloads/dispatch/dispatch.py start {project}"

    try:
        result = subprocess.run(
            cmd, shell=True, capture_output=True, text=True, timeout=60
        )
        print(f"    âœ… Dispatch å·²å¯åŠ¨")
    except Exception as e:
        return {"status": "error", "message": f"å¯åŠ¨å¤±è´¥: {e}"}

    # 2. ç­‰å¾…å¹¶æ£€æŸ¥çŠ¶æ€
    max_wait = DISPATCH_TIMEOUT
    interval = 30
    elapsed = 0

    while elapsed < max_wait:
        time.sleep(interval)
        elapsed += interval

        # æ£€æŸ¥çŠ¶æ€
        status_cmd = f"python3 ~/Downloads/dispatch/dispatch.py status {project}"
        status_result = subprocess.run(
            status_cmd, shell=True, capture_output=True, text=True, timeout=30
        )

        # è§£æçŠ¶æ€
        output = status_result.stdout
        if "completed" in output.lower() or "done" in output.lower():
            break
        elif "failed" in output.lower() or "error" in output.lower():
            return {"status": "failed", "output": output}

        print(f"    â³ ç­‰å¾…æ‰§è¡Œ... ({elapsed}s)")

    # 3. æ”¶é›†ç»“æœ
    return {"status": "timeout", "output": "ç­‰å¾…è¶…æ—¶"}


def collect_test_results(project: str) -> Tuple[int, int, str]:
    """æ”¶é›†æµ‹è¯•ç»“æœ

    Returns:
        (passed, total, error_msg)
    """
    print(f"    ğŸ“Š æ”¶é›†æµ‹è¯•ç»“æœ...")

    # å°è¯•è¯»å– dispatch æŠ¥å‘Š
    report_path = Path(f"~/Downloads/dispatch/{project}-merge_report.json")
    if report_path.exists():
        try:
            data = json.loads(report_path.read_text())
            # è§£ææŠ¥å‘Šç»“æ„
            # è¿™ä¸ªéœ€è¦æ ¹æ®å®é™…çš„æŠ¥å‘Šæ ¼å¼æ¥è§£æ
            passed = data.get("passed", 0)
            total = data.get("total", 0)
            return passed, total, ""
        except:
            pass

    # å°è¯•è¿è¡Œæµ‹è¯•å‘½ä»¤
    test_cmd = (
        f"cd ~/Downloads/{project} && python3 -m pytest --tb=no -q 2>&1 | tail -5"
    )
    try:
        result = subprocess.run(
            test_cmd, shell=True, capture_output=True, text=True, timeout=120
        )
        output = result.stdout + result.stderr

        # è§£æ pytest è¾“å‡º
        # ä¾‹å¦‚: "5 passed, 2 failed" æˆ– "7 passed"
        passed = 0
        total = 0

        match = re.search(r"(\d+) passed", output)
        if match:
            passed = int(match.group(1))

        match = re.search(r"(\d+) failed", output)
        if match:
            total = passed + int(match.group(1))
        elif passed > 0:
            total = passed

        if total > 0:
            return passed, total, ""

        return 0, 0, "æ— æ³•è§£ææµ‹è¯•ç»“æœ"

    except Exception as e:
        return 0, 0, f"æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}"


# ============== å¼ºéªŒæ”¶è¯„ä¼° ==============
@dataclass
class AcceptanceResult:
    """å¼ºéªŒæ”¶ç»“æœ"""

    pytest_passed: int = 0
    pytest_total: int = 0
    pytest_score: float = 0.0

    lint_passed: bool = False
    lint_score: float = 0.0

    mypy_passed: bool = False
    mypy_score: float = 0.0

    integration_passed: int = 0
    integration_total: int = 0
    integration_score: float = 0.0

    total_score: float = 0.0
    error_msg: str = ""


def run_strong_acceptance(project: str) -> AcceptanceResult:
    """è¿è¡Œå¼ºéªŒæ”¶æ ‡å‡†ï¼špytest + black + mypy + é›†æˆæµ‹è¯•"""
    result = AcceptanceResult()
    project_path = Path(f"~/Downloads/{project}").expanduser()

    # 1. Pytest (50%)
    print(f"    ğŸ”¬ è¿è¡Œ pytest...")
    pytest_cmd = f"cd {project_path} && python3 -m pytest --tb=no -q 2>&1"
    try:
        proc = subprocess.run(
            pytest_cmd, shell=True, capture_output=True, text=True, timeout=180
        )
        output = proc.stdout + proc.stderr

        # è§£æ pytest ç»“æœ
        passed = 0
        total = 0
        match = re.search(r"(\d+) passed", output)
        if match:
            passed = int(match.group(1))
        match = re.search(r"(\d+) failed", output)
        if match:
            total = passed + int(match.group(1))
        elif passed > 0:
            total = passed

        result.pytest_passed = passed
        result.pytest_total = total if total > 0 else 1
        result.pytest_score = (
            passed / result.pytest_total if result.pytest_total > 0 else 0
        )
        print(f"      pytest: {passed}/{total} = {result.pytest_score:.2f}")
    except Exception as e:
        result.error_msg += f"pytesté”™è¯¯: {e}; "

    # 2. Black/Flake8 (20%)
    print(f"    ğŸ” è¿è¡Œ black...")
    lint_passed = True
    for linter in ["black", "flake8"]:
        lint_cmd = f"cd {project_path} && python3 -m {linter} --check . 2>&1"
        try:
            proc = subprocess.run(
                lint_cmd, shell=True, capture_output=True, text=True, timeout=60
            )
            if proc.returncode != 0:
                lint_passed = False
                result.error_msg += f"{linter}å¤±è´¥; "
                break
        except:
            pass

    result.lint_passed = lint_passed
    result.lint_score = 1.0 if lint_passed else 0.0
    print(f"      lint: {'âœ“' if lint_passed else 'âœ—'} = {result.lint_score:.2f}")

    # 3. Mypy (20%)
    print(f"    ğŸ” è¿è¡Œ mypy...")
    mypy_cmd = f"cd {project_path} && python3 -m mypy . --ignore-missing-imports 2>&1"
    try:
        proc = subprocess.run(
            mypy_cmd, shell=True, capture_output=True, text=True, timeout=120
        )
        result.mypy_passed = proc.returncode == 0
        result.mypy_score = 1.0 if result.mypy_passed else 0.0
        if not result.mypy_passed:
            result.error_msg += "mypyå¤±è´¥; "
    except Exception as e:
        result.mypy_passed = False
        result.mypy_score = 0.0
        result.error_msg += f"mypyé”™è¯¯: {e}; "

    print(f"      mypy: {'âœ“' if result.mypy_passed else 'âœ—'} = {result.mypy_score:.2f}")

    # 4. é›†æˆæµ‹è¯• (10%) - å¦‚æœæœ‰ tests/integration ç›®å½•
    print(f"    ğŸŒ è¿è¡Œé›†æˆæµ‹è¯•...")
    integration_path = project_path / "tests" / "integration"
    if integration_path.exists():
        int_cmd = (
            f"cd {project_path} && python3 -m pytest tests/integration --tb=no -q 2>&1"
        )
        try:
            proc = subprocess.run(
                int_cmd, shell=True, capture_output=True, text=True, timeout=180
            )
            output = proc.stdout + proc.stderr

            passed = 0
            total = 0
            match = re.search(r"(\d+) passed", output)
            if match:
                passed = int(match.group(1))
            match = re.search(r"(\d+) failed", output)
            if match:
                total = passed + int(match.group(1))
            elif passed > 0:
                total = passed

            result.integration_passed = passed
            result.integration_total = total if total > 0 else 1
            result.integration_score = (
                passed / result.integration_total if result.integration_total > 0 else 0
            )
        except Exception as e:
            result.integration_score = 0.0
            result.error_msg += f"é›†æˆæµ‹è¯•é”™è¯¯: {e}; "
    else:
        result.integration_passed = 1
        result.integration_total = 1
        result.integration_score = 1.0  # æ— é›†æˆæµ‹è¯•ç›®å½• = è·³è¿‡

    print(
        f"      integration: {result.integration_passed}/{result.integration_total} = {result.integration_score:.2f}"
    )

    # è®¡ç®—æ€»åˆ†
    result.total_score = (
        result.pytest_score * WEIGHT_PYTEST
        + result.lint_score * WEIGHT_LINT
        + result.mypy_score * WEIGHT_MYPY
        + result.integration_score * WEIGHT_INTEGRATION
    )

    print(
        f"    ğŸ“Š å¼ºéªŒæ”¶æ€»åˆ†: {result.total_score:.2f} (pytest:{result.pytest_score * WEIGHT_PYTEST:.2f} + lint:{result.lint_score * WEIGHT_LINT:.2f} + mypy:{result.mypy_score * WEIGHT_MYPY:.2f} + integration:{result.integration_score * WEIGHT_INTEGRATION:.2f})"
    )

    return result


# ============== è¯„ä¼° ==============
def evaluate_individual(
    individual: SpecIndividual, project: str, test_cmd: str = None
) -> SpecIndividual:
    """è¯„ä¼°ä¸€ä¸ªä¸ªé«” - çœŸå®æ‰§è¡Œ + å¼ºéªŒæ”¶"""

    # 1. ä¿å­˜ spec
    spec_path = save_spec(
        individual.spec_content, project, individual.id, individual.generation
    )
    individual.code_path = spec_path
    print(f"    ğŸ“„ Spec å·²ä¿å­˜: {spec_path}")

    # 2. è°ƒç”¨ dispatch æ‰§è¡Œ
    dispatch_result = run_dispatch(project, spec_path)

    if dispatch_result["status"] == "error":
        individual.error_msg = dispatch_result.get("message", "Dispatch é”™è¯¯")
        individual.fitness = 0.0
        return individual

    # 3. è¿è¡Œå¼ºéªŒæ”¶æ ‡å‡†
    acceptance = run_strong_acceptance(project)
    individual.acceptance = acceptance

    individual.test_passed = acceptance.pytest_passed
    individual.test_total = acceptance.pytest_total
    individual.fitness = acceptance.total_score

    if acceptance.error_msg:
        individual.error_msg = acceptance.error_msg

    return individual


# ============== ç®€åŒ–ç‰ˆè¯„ä¼°ï¼ˆä¸éœ€è¦çœŸå® dispatchï¼‰==============
def evaluate_individual_mock(
    individual: SpecIndividual, project: str, test_cmd: str = None
) -> SpecIndividual:
    """æ¨¡æ‹Ÿè¯„ä¼° - ç”¨äºæµ‹è¯•ï¼ˆæ¨¡æ‹Ÿå¼ºéªŒæ”¶ï¼‰"""
    import random

    # æ¨¡æ‹Ÿå¼ºéªŒæ”¶å„é¡¹å¾—åˆ†
    pytest_score = random.uniform(0.3, 1.0)
    lint_score = random.choice([0.0, 1.0])
    mypy_score = random.choice([0.0, 1.0])
    integration_score = random.uniform(0.5, 1.0)

    # æ„å»ºæ¨¡æ‹ŸéªŒæ”¶ç»“æœ
    acceptance = AcceptanceResult()
    acceptance.pytest_passed = int(pytest_score * 10)
    acceptance.pytest_total = 10
    acceptance.pytest_score = pytest_score

    acceptance.lint_passed = lint_score == 1.0
    acceptance.lint_score = lint_score

    acceptance.mypy_passed = mypy_score == 1.0
    acceptance.mypy_score = mypy_score

    acceptance.integration_passed = int(integration_score * 3)
    acceptance.integration_total = 3
    acceptance.integration_score = integration_score

    acceptance.total_score = (
        pytest_score * WEIGHT_PYTEST
        + lint_score * WEIGHT_LINT
        + mypy_score * WEIGHT_MYPY
        + integration_score * WEIGHT_INTEGRATION
    )

    individual.acceptance = acceptance
    individual.fitness = acceptance.total_score
    individual.test_passed = acceptance.pytest_passed
    individual.test_total = acceptance.pytest_total

    if individual.fitness < 0.3:
        individual.error_msg = "æµ‹è¯•å¤±è´¥: æŸäº›æ–­è¨€æœªé€šè¿‡"

    return individual


# ============== è¿›åŒ–ç›¸å…³å‡½æ•° ==============
def build_generation_prompt(
    task: str,
    project: str,
    population: List[SpecIndividual],
    best_individual: Optional[SpecIndividual],
    all_tests: str,
    generation: int,
    max_gens: int = MAX_GENERATIONS,
    pop_size: int = POPULATION_SIZE,
) -> str:
    prompt = f"""ä½ æ˜¯ä¸€ä¸ª AI ä»£ç å·¥å‚çš„è¿›åŒ–ç®—æ³•å¼•æ“ï¼Œè´Ÿè´£ç”Ÿæˆèƒ½é€šè¿‡æ‰€æœ‰æµ‹è¯•çš„ä»£ç ã€‚

## ä»»åŠ¡
{task}

## é¡¹ç›®
{project}

## è½®æ¬¡
ç¬¬ {generation + 1} ä»£ (å…± {max_gens} ä»£)

## æµ‹è¯•ç”¨ä¾‹
{all_tests}

"""

    if best_individual:
        prompt += f"""
### æœ€ä½³è§£æ³• (fitness: {best_individual.fitness:.2f})
```
{best_individual.spec_content[:1000]}
```

é”™è¯¯åˆ†æ:
{best_individual.error_msg if best_individual.error_msg else "æ— "}
"""

    if population:
        prompt += "\n### è¿™ä¸€ä»£çš„è§£æ³•è¯„ä¼°\n"
        for ind in sorted(population, key=lambda x: x.fitness, reverse=True):
            prompt += f"""
- ID: {ind.id}
- Fitness: {ind.fitness:.2f} ({ind.test_passed}/{ind.test_total} æµ‹è¯•é€šè¿‡)
- é”™è¯¯: {ind.error_msg[:200] if ind.error_msg else "æ— "}
"""

    prompt += f"""
## è¿›åŒ–ç­–ç•¥æŒ‡å¯¼

æ ¹æ®ä¸Šä¸€ä»£çš„ç»“æœï¼Œä½ éœ€è¦ï¼š
1. å¦‚æœæœ‰ fitness >= 0.8 çš„è§£æ³•ï¼Œ**ä¿ç•™å¹¶æ”¹è¿›**å®ƒ
2. å¦‚æœæ‰€æœ‰è§£æ³•éƒ½å¤±è´¥ï¼Œ**æ”¹å˜æ€è·¯**ï¼Œå°è¯•å…¨æ–°æ–¹æ¡ˆ
3. å¦‚æœéƒ¨åˆ†æˆåŠŸä½†æœ‰é”™è¯¯ï¼Œ**ä¿®å¤é”™è¯¯**ï¼Œä¿æŒæ­£ç¡®éƒ¨åˆ†
4. å°è¯•ä¸åŒçš„**æŠ€æœ¯è·¯å¾„**ï¼ˆä¸åŒçš„åº“/æ¶æ„/ç®—æ³•ï¼‰

## è¾“å‡ºè¦æ±‚

ç”Ÿæˆ {pop_size} ä¸ªæ–°çš„ spec å˜ä½“ã€‚

æ¯ä¸ª spec å¿…é¡»ï¼š
1. æœ‰ä¸åŒçš„æŠ€æœ¯è·¯å¾„/å®ç°æ€è·¯
2. éªŒæ”¶æ ‡å‡†å¿…é¡»å¯æµ‹è¯•
3. åŒ…å«å…·ä½“çš„ä»£ç æ”¹åŠ¨

ç”¨ "---SPEC_SEPARATOR---" åˆ†éš”æ¯ä¸ª specã€‚
"""

    return prompt


SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ AI ä»£ç è¿›åŒ–ç®—æ³•å¼•æ“ã€‚

ä½ çš„ç›®æ ‡æ˜¯ç”Ÿæˆèƒ½**é€šè¿‡æ‰€æœ‰æµ‹è¯•**çš„ä»£ç è§£å†³æ–¹æ¡ˆã€‚

å…³é”®åŸåˆ™ï¼š
- æµ‹è¯•é€šè¿‡ = æ­£ç¡®
- æµ‹è¯•å¤±è´¥ = éœ€è¦æ”¹è¿›
- ç”¨æµ‹è¯•ç»“æœæŒ‡å¯¼ä½ çš„ç”Ÿæˆæ–¹å‘

è¾“å‡ºæ ¼å¼ï¼šç›´æ¥è¾“å‡º N ä¸ª specï¼Œç”¨ "---SPEC_SEPARATOR---" åˆ†éš”"""


def select_parents(population: List[SpecIndividual]) -> List[SpecIndividual]:
    if not population:
        return []
    sorted_pop = sorted(population, key=lambda x: x.fitness, reverse=True)
    return sorted_pop[: len(sorted_pop) // 2 + 1]


def generate_next_generation(
    task: str,
    project: str,
    population: List[SpecIndividual],
    all_tests: str,
    generation: int,
    pop_size: int = POPULATION_SIZE,
    max_gens: int = MAX_GENERATIONS,
) -> List[SpecIndividual]:
    best = max(population, key=lambda x: x.fitness) if population else None

    prompt = build_generation_prompt(
        task, project, population, best, all_tests, generation, max_gens, pop_size
    )

    print(f"  ğŸ”„ è°ƒç”¨ LLM ç”Ÿæˆç¬¬ {generation + 1} ä»£...")
    result = call_llm(prompt, system_prompt=SYSTEM_PROMPT, temperature=TEMPERATURE)

    if not result:
        print("  âš ï¸ LLM è¿”å›ç©ºï¼Œä½¿ç”¨ä¸Šä¸€ä»£æœ€ä½³")
        if best:
            return [
                SpecIndividual(
                    id=f"gen{generation + 1}_v{i}",
                    spec_content=best.spec_content,
                    generation=generation + 1,
                )
                for i in range(pop_size)
            ]
        return []

    specs = result.split("---SPEC_SEPARATOR---")
    specs = [s.strip() for s in specs if s.strip()]

    new_population = []
    for i, spec in enumerate(specs[:pop_size]):
        ind = SpecIndividual(
            id=f"gen{generation + 1}_v{i + 1}",
            spec_content=spec,
            generation=generation + 1,
            parent_ids=[p.id for p in select_parents(population)],
        )
        new_population.append(ind)

    while len(new_population) < pop_size:
        if best:
            new_population.append(
                SpecIndividual(
                    id=f"gen{generation + 1}_v{len(new_population) + 1}",
                    spec_content=best.spec_content,
                    generation=generation + 1,
                    mutations=best.mutations + 1,
                )
            )
        else:
            break

    return new_population


# ============== ä¸»å¾ªç¯ ==============
def collision_loop(
    task: str,
    project: str,
    test_cmd: str = None,
    all_tests: str = "",
    max_gens: int = MAX_GENERATIONS,
    pop_size: int = POPULATION_SIZE,
    mock: bool = False,
) -> Dict:
    """ç¢°æ’ä¸»å¾ªç¯"""

    print(f"\n{'=' * 60}")
    print(f"ğŸ¯ Spec ç¢°æ’ç³»ç»Ÿ v2 (LLaMEA-style)")
    print(f"ğŸ“‹ ä»»åŠ¡: {task}")
    print(f"ğŸ“ é¡¹ç›®: {project}")
    print(f"âš™ï¸  é…ç½®: {pop_size} ä¸ªä½“/ä»£, {max_gens} ä»£")
    print(f"ğŸ”§ æ¨¡å¼: {'æ¨¡æ‹Ÿ' if mock else 'çœŸå®æ‰§è¡Œ'}")
    print(f"{'=' * 60}\n")

    # é€‰æ‹©è¯„ä¼°å‡½æ•°
    evaluator = evaluate_individual_mock if mock else evaluate_individual

    population = []
    best_ever = None
    all_history = []

    for generation in range(max_gens):
        print(f"\nğŸ“Œ ç¬¬ {generation + 1}/{max_gens} ä»£")

        if generation == 0:
            print("  ğŸ² ç¬¬ä¸€ä»£ï¼šéšæœºç”Ÿæˆ...")
            new_pop = generate_next_generation(
                task, project, [], all_tests, generation, pop_size, max_gens
            )
        else:
            print("  ğŸ§¬ è¿›åŒ–ç”Ÿæˆ...")
            new_pop = generate_next_generation(
                task, project, population, all_tests, generation, pop_size, max_gens
            )

        if not new_pop:
            print("  âš ï¸ ç”Ÿæˆå¤±è´¥ï¼Œå°è¯•é‡å¯...")
            new_pop = generate_next_generation(
                task, project, [], all_tests, generation, pop_size, max_gens
            )
            if not new_pop:
                print("  âŒ è¿ç»­ç”Ÿæˆå¤±è´¥ï¼Œåœæ­¢")
                break

        # è¯„ä¼°æ¯ä¸ªä¸ªä½“
        print(f"  ğŸ“Š è¯„ä¼° {len(new_pop)} ä¸ªä¸ªä½“...")
        for ind in new_pop:
            ind = evaluator(ind, project, test_cmd)
            print(
                f"    {ind.id}: fitness={ind.fitness:.2f} ({ind.test_passed}/{ind.test_total})"
            )

        all_history.extend(new_pop)

        current_best = max(new_pop, key=lambda x: x.fitness)
        if best_ever is None or current_best.fitness > best_ever.fitness:
            best_ever = current_best
            print(f"  â­ æ–°æœ€ä½³: {best_ever.id}, fitness={best_ever.fitness:.2f}")

        if best_ever.fitness >= 1.0:
            print(f"\nğŸ‰ æ‰¾åˆ°å®Œç¾è§£ï¼ fitness=1.0")
            break

        population = new_pop

        avg_fitness = sum(ind.fitness for ind in population) / len(population)
        print(f"  ğŸ“ˆ å¹³å‡ fitness: {avg_fitness:.2f}")

        if generation > 5 and avg_fitness < 0.1:
            print("  âš ï¸ è¿ç»­ä½ fitnessï¼Œé‡å¯æ€è·¯...")
            population = []

    return {
        "task": task,
        "project": project,
        "generations": generation + 1,
        "best_individual": best_ever,
        "history": all_history,
        "success": best_ever.fitness >= 0.8 if best_ever else False,
    }


# ============== CLI ==============
def main():
    parser = argparse.ArgumentParser(description="Spec ç¢°æ’ç³»ç»Ÿ v2 - LLaMEA é£æ ¼")
    parser.add_argument("task", help="ä»»åŠ¡ç›®æ ‡")
    parser.add_argument("-p", "--project", required=True, help="é¡¹ç›®å")
    parser.add_argument("-t", "--test", help="æµ‹è¯•å‘½ä»¤")
    parser.add_argument("--tests", help="æµ‹è¯•ç”¨ä¾‹å†…å®¹")
    parser.add_argument(
        "-g", "--generations", type=int, default=MAX_GENERATIONS, help="æœ€å¤§ä»£æ•°"
    )
    parser.add_argument(
        "-n", "--population", type=int, default=POPULATION_SIZE, help="æ¯ä»£ä¸ªä½“æ•°"
    )
    parser.add_argument(
        "--mock", action="store_true", help="ä½¿ç”¨æ¨¡æ‹Ÿè¯„ä¼°ï¼ˆä¸çœŸå®æ‰§è¡Œï¼‰"
    )

    args = parser.parse_args()

    result = collision_loop(
        args.task,
        args.project,
        args.test,
        args.tests or "",
        args.generations,
        args.population,
        args.mock,
    )

    print(f"\n{'=' * 60}")
    print(f"ğŸ ç¢°æ’å®Œæˆ")
    print(f"ä»£æ•°: {result['generations']}")
    print(f"æˆåŠŸ: {result['success']}")
    if result["best_individual"]:
        print(f"æœ€ä½³ fitness: {result['best_individual'].fitness:.2f}")
    print(f"{'=' * 60}")


if __name__ == "__main__":
    main()
