#!/usr/bin/env python3
"""
æ‹œå åº­å¯¹æ’å™¨ (Byzantine Collider) MVP
AI-to-AI äº§å“ç¢°æ’ç³»ç»Ÿ

Usage:
    python3 byzantine_collider.py --topic "æ‹œå åº­å¯¹æ’å™¨å•†ä¸šåŒ–"
    python3 byzantine_collider.py --topic "æ˜¯å¦åº”è¯¥åšå°ç¨‹åº"
    python3 byzantine_collider.py --topic "AI äº§å“" --llm zhipu
"""

import argparse
import json
import os
import sys
import time
from datetime import datetime
from typing import Optional

# LLM é€‚é…å±‚
try:
    from llm import create_llm, get_default_llm

    LLM_ADAPTER_AVAILABLE = True
except ImportError:
    LLM_ADAPTER_AVAILABLE = False
    print("âš ï¸ è­¦å‘Š: llm.py æœªæ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤å®ç°")

# é»˜è®¤å®ç°ï¼ˆå…¼å®¹ï¼‰
try:
    from openai import OpenAI

    CLIENT = OpenAI()
except ImportError:
    CLIENT = None


# ============ Prompt æ¨¡æ¿ ============

CHALLENGER_SYSTEM = """ä½ æ˜¯ä¸€ä½æ¿€è¿›çš„äº§å“æ‰¹è¯„å®¶ï¼Œä¸“é—¨æ‰¾é—®é¢˜ã€æŒ‘æ¯›ç—…ã€è´¨ç–‘ä¸€åˆ‡å‡è®¾ã€‚

æ ¸å¿ƒä»»åŠ¡ï¼š
- è´¨ç–‘"{topic}"çš„å¯è¡Œæ€§
- æŒ‘æˆ˜ä»»ä½•å‡è®¾
- æŒ‡å‡ºæ½œåœ¨é£é™©å’Œé™·é˜±

æé—®é£æ ¼ï¼š
- "ä½†æ˜¯å¦‚æœ...æ€ä¹ˆåŠï¼Ÿ"
- "è¿™ä¸ªå‡è®¾çœŸçš„æˆç«‹å—ï¼Ÿ"
- "å¸‚åœºè§„æ¨¡çœŸçš„å¤Ÿå¤§å—ï¼Ÿ"
- "ç”¨æˆ·çœŸçš„ä¼šä¸ºæ­¤ä»˜è´¹å—ï¼Ÿ"

çº¦æŸï¼š
- åªæé—®å’Œè´¨ç–‘ï¼Œä¸ç»™è§£å†³æ–¹æ¡ˆ
- é—®é¢˜è¦å…·ä½“ã€æœ‰æŒ‘æˆ˜æ€§
- è‡³å°‘åˆ—å‡º 5 ä¸ªæŒ‘æˆ˜ç‚¹
- ç”¨ä¸­æ–‡è¾“å‡º"""

DEFENDER_SYSTEM = """ä½ æ˜¯ä¸€ä½åšå®šçš„äº§å“è¾©æŠ¤è€…ï¼Œä¸º"{topic}"è¾©æŠ¤ã€‚

æ ¸å¿ƒä»»åŠ¡ï¼š
- ä¸ºæ–¹æ¡ˆçš„å•†ä¸šåŒ–æ¨¡å¼è¾©æŠ¤
- åé©³æŒ‘æˆ˜è€…çš„è´¨ç–‘
- æä¾›å…·ä½“çš„è¯æ®å’Œæ¨ç†

å›åº”é£æ ¼ï¼š
- "è¿™ä¸ªæŒ‘æˆ˜æœ‰é“ç†ï¼Œä½†æˆ‘ä»¬å¯ä»¥..."
- "å®é™…ä¸Šï¼Œæ•°æ®è¡¨æ˜..."
- "ç«äº‰å¯¹æ‰‹ XXX å·²ç»éªŒè¯äº†..."

çº¦æŸï¼š
- å¿…é¡»å›åº”æ¯ä¸€ä¸ªæŒ‘æˆ˜
- æä¾›å…·ä½“çš„æ•°æ®ã€æ¡ˆä¾‹ã€æˆ–æ¨ç†
- ä¸è¦è½»æ˜“å¦¥å
- ç”¨ä¸­æ–‡è¾“å‡º"""


# ============ æ ¸å¿ƒå‡½æ•° ============

# å…¨å±€ LLM å®ä¾‹
_llm_instance = None


def get_llm(provider: str = None) -> Optional[object]:
    """è·å– LLM å®ä¾‹"""
    global _llm_instance

    if _llm_instance is not None:
        return _llm_instance

    if LLM_ADAPTER_AVAILABLE:
        _llm_instance = get_default_llm()
        return _llm_instance

    return None


def call_llm(
    system_prompt: str, user_prompt: str, model: str = None, provider: str = None
) -> str:
    """è°ƒç”¨ LLM"""

    # ä¼˜å…ˆä½¿ç”¨ LLM é€‚é…å™¨
    llm = get_llm(provider)
    if llm:
        return llm.chat(system_prompt, user_prompt)

    # å›é€€åˆ°é»˜è®¤å®ç°
    if CLIENT is None:
        return "[æ¨¡æ‹Ÿè¾“å‡º] è¯·é…ç½® API key"

    response = CLIENT.chat.completions.create(
        model=model or "gpt-4o",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ],
        temperature=0.8,
    )
    content = response.choices[0].message.content
    return content if content is not None else ""


def phase1_initialize(topic: str) -> dict:
    """é˜¶æ®µ1ï¼šåˆå§‹åŒ– - ç”ŸæˆæŒ‘æˆ˜è€…å’Œè¾©æŠ¤è€…ç«‹åœº"""
    print(f"\nğŸ“ é˜¶æ®µ1ï¼šåˆå§‹åŒ– - ä¸»é¢˜: {topic}")

    # æŒ‘æˆ˜è€…ç”ŸæˆæŒ‘æˆ˜
    challenger_prompt = f"""è¯·åˆ—å‡ºä½ å¯¹"{topic}"çš„æ‰€æœ‰è´¨ç–‘å’ŒæŒ‘æˆ˜ã€‚"""
    challenger_output = call_llm(
        CHALLENGER_SYSTEM.format(topic=topic), challenger_prompt
    )

    # è¾©æŠ¤è€…ç”Ÿæˆå›åº”
    defender_prompt = f"""æŒ‘æˆ˜è€…æå‡ºäº†ä»¥ä¸‹è´¨ç–‘ï¼Œè¯·ä¸º"{topic}"è¾©æŠ¤ï¼š
    
{challenger_output}"""
    defender_output = call_llm(DEFENDER_SYSTEM.format(topic=topic), defender_prompt)

    return {
        "phase": 1,
        "topic": topic,
        "challenger": challenger_output,
        "defender": defender_output,
        "timestamp": datetime.now().isoformat(),
    }


def phase2_iterate(topic: str, previous: dict, round_num: int) -> dict:
    """é˜¶æ®µ2ï¼šè¿­ä»£ç¢°æ’"""
    print(f"\nğŸ”„ é˜¶æ®µ2ï¼šç¬¬ {round_num} è½®ç¢°æ’")

    # æŒ‘æˆ˜è€…æ”»å‡»
    challenger_prompt = f"""ä¸»é¢˜ï¼š{topic}

ä¸Šä¸€è½®è¾©æŠ¤è€…çš„å›åº”ï¼š
{previous.get("defender", "")}

è¯·æ‰¾å‡ºè¾©æŠ¤è€…å›åº”çš„é€»è¾‘æ¼æ´ã€è¯æ®ç¼ºé™·ï¼Œå¹¶ç”¨åä¾‹æ”»å‡»ã€‚"""
    challenger_output = call_llm(
        CHALLENGER_SYSTEM.format(topic=topic), challenger_prompt
    )

    # è¾©æŠ¤è€…é˜²å¾¡
    defender_prompt = f"""ä¸»é¢˜ï¼š{topic}

æŒ‘æˆ˜è€…çš„æ–°ä¸€è½®æ”»å‡»ï¼š
{challenger_output}

è¯·å›åº”è¿™äº›æ”»å‡»ï¼Œå¼ºåŒ–ä½ çš„è®ºç‚¹ã€‚"""
    defender_output = call_llm(DEFENDER_SYSTEM.format(topic=topic), defender_prompt)

    return {
        "phase": 2,
        "round": round_num,
        "challenger": challenger_output,
        "defender": defender_output,
        "timestamp": datetime.now().isoformat(),
    }


def phase3_converge(topic: str, history: list) -> dict:
    """é˜¶æ®µ3ï¼šæ”¶æ•›åˆ¤å®š - ç”Ÿæˆå…±è¯†å’Œåˆ†æ­§"""
    print(f"\nâœ… é˜¶æ®µ3ï¼šæ”¶æ•›åˆ¤å®š")

    # æ±‡æ€»æ‰€æœ‰ç¢°æ’å†å²
    history_text = "\n\n".join(
        [
            f"ç¬¬{round['round']}è½®:\næŒ‘æˆ˜è€…: {round['challenger']}\nè¾©æŠ¤è€…: {round['defender']}"
            for round in history
        ]
    )

    converge_prompt = f"""åŸºäºä»¥ä¸‹ç¢°æ’å†å²ï¼Œè¯·æ€»ç»“ï¼š

1. å…±è¯†ç‚¹ï¼ˆåŒæ–¹åŒæ„çš„ï¼‰
2. åˆ†æ­§ç‚¹ï¼ˆä»å­˜åœ¨äº‰è®®çš„ï¼‰
3. ç½®ä¿¡åº¦è¯„åˆ†ï¼ˆ1-10ï¼‰
4. ç»“è®ºæ‘˜è¦

ç¢°æ’å†å²ï¼š
{history_text}"""

    # ç”¨æŒ‘æˆ˜è€…æ¨¡æ¿åšæ€»ç»“ï¼ˆæ‰¹åˆ¤æ€§è§†è§’ï¼‰
    summary = call_llm(
        CHALLENGER_SYSTEM.format(topic=topic),  # å¤ç”¨æ¨¡æ¿
        converge_prompt,
    )

    return {"phase": 3, "summary": summary, "timestamp": datetime.now().isoformat()}


def run_collision(
    topic: str, max_rounds: int = 3, output_file: Optional[str] = None
) -> dict:
    """è¿è¡Œå®Œæ•´çš„æ‹œå åº­å¯¹æ’"""

    print(f"\n{'=' * 50}")
    print(f"ğŸš€ æ‹œå åº­å¯¹æ’å™¨å¯åŠ¨")
    print(f"ğŸ“Œ ä¸»é¢˜: {topic}")
    print(f"ğŸ”„ æœ€å¤§è½®æ¬¡: {max_rounds}")
    print(f"{'=' * 50}")

    # é˜¶æ®µ1ï¼šåˆå§‹åŒ–
    result = phase1_initialize(topic)
    history = [result]

    # é˜¶æ®µ2ï¼šè¿­ä»£ç¢°æ’
    for round_num in range(2, max_rounds + 1):
        result = phase2_iterate(topic, history[-1], round_num)
        history.append(result)
        print(f"   ç¬¬ {round_num} è½®å®Œæˆ")

    # é˜¶æ®µ3ï¼šæ”¶æ•›
    convergence = phase3_converge(topic, history)

    # å®Œæ•´ç»“æœ
    full_result = {
        "topic": topic,
        "timestamp": datetime.now().isoformat(),
        "rounds": max_rounds,
        "history": history,
        "convergence": convergence,
    }

    # ä¿å­˜ç»“æœ
    if output_file:
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(full_result, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜: {output_file}")

    return full_result


# ============ ä¸»å…¥å£ ============

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="æ‹œå åº­å¯¹æ’å™¨ MVP")
    parser.add_argument("--topic", "-t", required=True, help="ç¢°æ’ä¸»é¢˜")
    parser.add_argument("--rounds", "-r", type=int, default=3, help="ç¢°æ’è½®æ¬¡ (é»˜è®¤3)")
    parser.add_argument("--output", "-o", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")

    args = parser.parse_args()

    if not CLIENT:
        print("âš ï¸ è­¦å‘Š: æœªå®‰è£… openai åº“ï¼Œä½¿ç”¨æ¨¡æ‹Ÿè¾“å‡º")
        print("   å®‰è£…: pip install openai")

    result = run_collision(args.topic, args.rounds, args.output)

    print(f"\n{'=' * 50}")
    print(f"ğŸ å¯¹æ’å®Œæˆ")
    print(f"{'=' * 50}")
